{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Case Overview\n",
    "\n",
    "You're working as a data scientist for a contracting firm that's rapidly expanding. Now that they have their most valuable employee (you!), they need to leverage data to win more contracts. Your firm offers technology and scientific solutions and wants to be competitive in the hiring market. Your principal has two main objectives:\n",
    "\n",
    "   1. Determine the industry factors that are most important in predicting the salary amounts for these data.\n",
    "   2. Determine the factors that distinguish job categories and titles from each other. For example, can required skills accurately predict job title?\n",
    "\n",
    "To limit the scope, your principal has suggested that you *focus on data-related job postings*, e.g. data scientist, data analyst, research scientist, business intelligence, and any others you might think of. You may also want to decrease the scope by *limiting your search to a single region.*\n",
    "\n",
    "Hint: Aggregators like [Indeed.com](https://www.indeed.com) regularly pool job postings from a variety of markets and industries. \n",
    "\n",
    "**Goal:** Scrape your own data from a job aggregation tool like Indeed.com in order to collect the data to best answer these two questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directions\n",
    "\n",
    "In this project you will be leveraging a variety of skills. The first will be to use the web-scraping and/or API techniques you've learned to collect data on data jobs from Indeed.com or another aggregator. Once you have collected and cleaned the data, you will use it to answer the two questions described above.\n",
    "\n",
    "### QUESTION 1: Factors that impact salary\n",
    "\n",
    "To predict salary you will be building either a classification or regression model, using features like the location, title, and summary of the job. If framing this as a regression problem, you will be estimating the listed salary amounts. You may instead choose to frame this as a classification problem, in which case you will create labels from these salaries (high vs. low salary, for example) according to thresholds (such as median salary).\n",
    "\n",
    "You have learned a variety of new skills and models that may be useful for this problem:\n",
    "- NLP\n",
    "- Unsupervised learning and dimensionality reduction techniques (PCA, clustering)\n",
    "- Ensemble methods and decision tree models\n",
    "- SVM models\n",
    "\n",
    "Whatever you decide to use, the most important thing is to justify your choices and interpret your results. *Communication of your process is key.* Note that most listings **DO NOT** come with salary information. You'll need to able to extrapolate or predict the expected salaries for these listings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#question 1\n",
    "#Scrape and prepare your own data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import requests\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visit our relevant page.\n",
    "driver = webdriver.Chrome(executable_path=\"./chromedriver/chromedriver\")\n",
    "driver.get(\"https://www.mycareersfuture.sg/\")\n",
    "# Wait 3 second.\n",
    "sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the search job.\n",
    "elem = driver.find_element_by_name(\"search-text\")\n",
    "# Clear it.\n",
    "elem.clear()\n",
    "# Type in \"data\"\n",
    "elem.send_keys(\"data\")\n",
    "# Send the keys\n",
    "elem.send_keys(Keys.RETURN)\n",
    "# Wait 5 second.\n",
    "sleep(5)\n",
    "# Close it.\n",
    "# driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.mycareersfuture.sg/search?search=data&sortBy=new_posting_date&page=0\n"
     ]
    }
   ],
   "source": [
    "#grab current url\n",
    "url_page = driver.current_url\n",
    "print(url_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 0\n",
      "20\n",
      "Page 1\n",
      "20\n",
      "Page 2\n",
      "20\n",
      "Page 3\n",
      "20\n",
      "Page 4\n",
      "20\n",
      "Page 5\n",
      "20\n",
      "Page 6\n",
      "20\n",
      "Page 7\n",
      "20\n",
      "Page 8\n",
      "20\n",
      "Page 9\n",
      "20\n",
      "Page 10\n",
      "20\n",
      "Page 11\n",
      "20\n",
      "Page 12\n",
      "20\n",
      "Page 13\n",
      "20\n",
      "Page 14\n",
      "20\n",
      "Page 15\n",
      "20\n",
      "Page 16\n",
      "20\n",
      "Page 17\n",
      "20\n",
      "Page 18\n",
      "20\n",
      "Page 19\n",
      "20\n",
      "Page 20\n",
      "20\n",
      "Page 21\n",
      "20\n",
      "Page 22\n",
      "20\n",
      "Page 23\n",
      "20\n",
      "Page 24\n",
      "20\n",
      "Page 25\n",
      "20\n",
      "Page 26\n",
      "20\n",
      "Page 27\n",
      "20\n",
      "Page 28\n",
      "20\n",
      "Page 29\n",
      "20\n",
      "Page 30\n",
      "20\n",
      "Page 31\n",
      "20\n",
      "Page 32\n",
      "20\n",
      "Page 33\n",
      "20\n",
      "Page 34\n",
      "20\n",
      "Page 35\n",
      "20\n",
      "Page 36\n",
      "20\n",
      "Page 37\n",
      "20\n",
      "Page 38\n",
      "20\n",
      "Page 39\n",
      "20\n",
      "Page 40\n",
      "20\n",
      "Page 41\n",
      "20\n",
      "Page 42\n",
      "20\n",
      "Page 43\n",
      "20\n",
      "Page 44\n",
      "20\n",
      "Page 45\n",
      "20\n",
      "Page 46\n",
      "20\n",
      "Page 47\n",
      "20\n",
      "Page 48\n",
      "20\n",
      "Page 49\n",
      "20\n",
      "Page 50\n",
      "20\n",
      "Page 51\n",
      "20\n",
      "Page 52\n",
      "20\n",
      "Page 53\n",
      "20\n",
      "Page 54\n",
      "20\n",
      "Page 55\n",
      "20\n",
      "Page 56\n",
      "20\n",
      "Page 57\n",
      "20\n",
      "Page 58\n",
      "20\n",
      "Page 59\n",
      "20\n",
      "Page 60\n",
      "20\n",
      "Page 61\n",
      "20\n",
      "Page 62\n",
      "20\n",
      "Page 63\n",
      "20\n",
      "Page 64\n",
      "20\n",
      "Page 65\n",
      "20\n",
      "Page 66\n",
      "20\n",
      "Page 67\n",
      "20\n",
      "Page 68\n",
      "20\n",
      "Page 69\n",
      "20\n",
      "Page 70\n",
      "20\n",
      "Page 71\n",
      "20\n",
      "Page 72\n",
      "20\n",
      "Page 73\n",
      "20\n",
      "Page 74\n",
      "20\n",
      "Page 75\n",
      "20\n",
      "Page 76\n",
      "20\n",
      "Page 77\n",
      "20\n",
      "Page 78\n",
      "20\n",
      "Page 79\n",
      "20\n",
      "Page 80\n",
      "20\n",
      "Page 81\n",
      "20\n",
      "Page 82\n",
      "20\n",
      "Page 83\n",
      "20\n",
      "Page 84\n",
      "20\n",
      "Page 85\n",
      "20\n",
      "Page 86\n",
      "20\n",
      "Page 87\n",
      "20\n",
      "Page 88\n",
      "20\n",
      "Page 89\n",
      "20\n",
      "Page 90\n",
      "20\n",
      "Page 91\n",
      "20\n",
      "Page 92\n",
      "20\n",
      "Page 93\n",
      "20\n",
      "Page 94\n",
      "20\n",
      "Page 95\n",
      "20\n",
      "Page 96\n",
      "20\n",
      "Page 97\n",
      "20\n",
      "Page 98\n",
      "20\n",
      "Page 99\n",
      "20\n",
      "Page 100\n",
      "20\n",
      "Page 101\n",
      "20\n",
      "Page 102\n",
      "20\n",
      "Page 103\n",
      "20\n",
      "Page 104\n",
      "20\n",
      "Page 105\n",
      "20\n",
      "Page 106\n",
      "20\n",
      "Page 107\n",
      "20\n",
      "Page 108\n",
      "20\n",
      "Page 109\n",
      "20\n",
      "Page 110\n",
      "20\n",
      "Page 111\n",
      "20\n",
      "Page 112\n",
      "20\n",
      "Page 113\n",
      "20\n",
      "Page 114\n",
      "20\n",
      "Page 115\n",
      "20\n",
      "Page 116\n",
      "20\n",
      "Page 117\n",
      "20\n",
      "Page 118\n",
      "20\n",
      "Page 119\n",
      "20\n",
      "Page 120\n",
      "20\n",
      "Page 121\n",
      "20\n",
      "Page 122\n",
      "20\n",
      "Page 123\n",
      "20\n",
      "Page 124\n",
      "20\n",
      "Page 125\n",
      "20\n",
      "Page 126\n",
      "20\n",
      "Page 127\n",
      "20\n",
      "Page 128\n",
      "20\n",
      "Page 129\n",
      "20\n",
      "Page 130\n",
      "20\n",
      "Page 131\n",
      "20\n",
      "Page 132\n",
      "20\n",
      "Page 133\n",
      "20\n",
      "Page 134\n",
      "20\n",
      "Page 135\n",
      "20\n",
      "Page 136\n",
      "20\n",
      "Page 137\n",
      "20\n",
      "Page 138\n",
      "20\n",
      "Page 139\n",
      "20\n",
      "Page 140\n",
      "20\n",
      "Page 141\n",
      "20\n",
      "Page 142\n",
      "20\n",
      "Page 143\n",
      "20\n",
      "Page 144\n",
      "20\n",
      "Page 145\n",
      "20\n",
      "Page 146\n",
      "20\n",
      "Page 147\n",
      "20\n",
      "Page 148\n",
      "20\n",
      "Page 149\n",
      "20\n",
      "Page 150\n",
      "20\n",
      "Page 151\n",
      "20\n",
      "Page 152\n",
      "20\n",
      "Page 153\n",
      "20\n",
      "Page 154\n",
      "20\n",
      "Page 155\n",
      "20\n",
      "Page 156\n",
      "20\n",
      "Page 157\n",
      "20\n",
      "Page 158\n",
      "20\n",
      "Page 159\n",
      "20\n",
      "Page 160\n",
      "20\n",
      "Page 161\n",
      "20\n",
      "Page 162\n",
      "20\n",
      "Page 163\n",
      "20\n",
      "Page 164\n",
      "20\n",
      "Page 165\n",
      "20\n",
      "Page 166\n",
      "20\n",
      "Page 167\n",
      "20\n",
      "Page 168\n",
      "20\n",
      "Page 169\n",
      "20\n",
      "Page 170\n",
      "20\n",
      "Page 171\n",
      "20\n",
      "Page 172\n",
      "20\n",
      "Page 173\n",
      "20\n",
      "Page 174\n",
      "20\n",
      "Page 175\n",
      "20\n",
      "Page 176\n",
      "20\n",
      "Page 177\n",
      "20\n",
      "Page 178\n",
      "20\n",
      "Page 179\n",
      "20\n",
      "Page 180\n",
      "20\n",
      "Page 181\n",
      "20\n",
      "Page 182\n",
      "20\n",
      "Page 183\n",
      "20\n",
      "Page 184\n",
      "20\n",
      "Page 185\n",
      "20\n",
      "Page 186\n",
      "20\n",
      "Page 187\n",
      "20\n",
      "Page 188\n",
      "20\n",
      "Page 189\n",
      "20\n",
      "Page 190\n",
      "20\n",
      "Page 191\n",
      "20\n",
      "Page 192\n",
      "20\n",
      "Page 193\n",
      "20\n",
      "Page 194\n",
      "20\n",
      "Page 195\n",
      "20\n",
      "Page 196\n",
      "20\n",
      "Page 197\n",
      "20\n",
      "Page 198\n",
      "20\n",
      "Page 199\n",
      "20\n",
      "Total URL 4000\n",
      "==Done==\n"
     ]
    }
   ],
   "source": [
    "#Each url got 20job listings. Have to grab all the urls when navigating through the pages\n",
    "url_list=[]\n",
    "url = url_page.replace(\"0\",\"{}\")\n",
    "#url = \"https://www.mycareersfuture.sg/search?search=data&sortBy=new_posting_date&page={}\"\n",
    "for page in range(0,200):\n",
    "    print('Page {}'.format(page))\n",
    "    driver.get(url.format(page))\n",
    "    sleep(5)\n",
    "    soup = driver.page_source\n",
    "    soup = BeautifulSoup(soup, 'lxml')\n",
    "    job_links = [a['href'] for a in soup.find_all('a', href=True) if '/job/' in a['href']]\n",
    "    print(len(job_links))\n",
    "    for i in job_links:\n",
    "        url_list.append('https://www.mycareersfuture.sg' + i)\n",
    "print ('Total URL', len(url_list))\n",
    "print ('==Done==')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.mycareersfuture.sg/job/data-engineer-moneysmart-singapore-d56b1a5839b83d1bf6486c4beb22ed91\n"
     ]
    }
   ],
   "source": [
    "print(url_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a new data frame for jobs\n",
    "import pandas as pd\n",
    "jobs = pd.DataFrame(columns=[\"company\",\"job_title\",\"address\",\"employment_type\",\"seniority\",\"category\", \"salary\", \"salary_period\",\"requirements\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 records done\n",
      "10 records done\n",
      "20 records done\n",
      "30 records done\n",
      "40 records done\n",
      "50 records done\n",
      "60 records done\n",
      "70 records done\n",
      "80 records done\n",
      "90 records done\n",
      "100 records done\n",
      "110 records done\n",
      "120 records done\n",
      "130 records done\n",
      "140 records done\n",
      "150 records done\n",
      "160 records done\n",
      "170 records done\n",
      "180 records done\n",
      "190 records done\n",
      "200 records done\n",
      "210 records done\n",
      "220 records done\n",
      "230 records done\n",
      "240 records done\n",
      "250 records done\n",
      "260 records done\n",
      "270 records done\n",
      "280 records done\n",
      "290 records done\n",
      "300 records done\n",
      "310 records done\n",
      "320 records done\n",
      "330 records done\n",
      "340 records done\n",
      "350 records done\n",
      "360 records done\n",
      "370 records done\n",
      "380 records done\n",
      "390 records done\n",
      "400 records done\n",
      "410 records done\n",
      "420 records done\n",
      "430 records done\n",
      "440 records done\n",
      "450 records done\n",
      "460 records done\n",
      "470 records done\n",
      "480 records done\n",
      "490 records done\n",
      "500 records done\n",
      "510 records done\n",
      "520 records done\n",
      "530 records done\n",
      "540 records done\n",
      "550 records done\n",
      "560 records done\n",
      "570 records done\n",
      "580 records done\n",
      "590 records done\n",
      "600 records done\n",
      "610 records done\n",
      "620 records done\n",
      "630 records done\n",
      "640 records done\n",
      "650 records done\n",
      "660 records done\n",
      "670 records done\n",
      "680 records done\n",
      "690 records done\n",
      "700 records done\n",
      "710 records done\n",
      "720 records done\n",
      "730 records done\n",
      "740 records done\n",
      "750 records done\n",
      "760 records done\n",
      "770 records done\n",
      "780 records done\n",
      "790 records done\n",
      "800 records done\n",
      "810 records done\n",
      "820 records done\n",
      "830 records done\n",
      "840 records done\n",
      "850 records done\n",
      "860 records done\n",
      "870 records done\n",
      "880 records done\n",
      "890 records done\n",
      "900 records done\n",
      "910 records done\n",
      "920 records done\n",
      "930 records done\n",
      "940 records done\n",
      "950 records done\n",
      "960 records done\n",
      "970 records done\n",
      "980 records done\n",
      "990 records done\n",
      "1000 records done\n",
      "1010 records done\n",
      "1020 records done\n",
      "1030 records done\n",
      "1040 records done\n",
      "1050 records done\n",
      "1060 records done\n",
      "1070 records done\n",
      "1080 records done\n",
      "1090 records done\n",
      "1100 records done\n",
      "1110 records done\n",
      "1120 records done\n",
      "1130 records done\n",
      "1140 records done\n",
      "1150 records done\n",
      "1160 records done\n",
      "1170 records done\n",
      "1180 records done\n",
      "1190 records done\n",
      "1200 records done\n",
      "1210 records done\n",
      "1220 records done\n",
      "1230 records done\n",
      "1240 records done\n",
      "1250 records done\n",
      "1260 records done\n",
      "1270 records done\n",
      "1280 records done\n",
      "1290 records done\n",
      "1300 records done\n",
      "1310 records done\n",
      "1320 records done\n",
      "1330 records done\n",
      "1340 records done\n",
      "1350 records done\n",
      "1360 records done\n",
      "1370 records done\n",
      "1380 records done\n",
      "1390 records done\n",
      "1400 records done\n",
      "1410 records done\n",
      "1420 records done\n",
      "1430 records done\n",
      "1440 records done\n",
      "1450 records done\n",
      "1460 records done\n",
      "1470 records done\n",
      "1480 records done\n",
      "1490 records done\n",
      "1500 records done\n",
      "1510 records done\n",
      "1520 records done\n",
      "1530 records done\n",
      "1540 records done\n",
      "1550 records done\n",
      "1560 records done\n",
      "1570 records done\n",
      "1580 records done\n",
      "1590 records done\n",
      "1600 records done\n",
      "1610 records done\n",
      "1620 records done\n",
      "1630 records done\n",
      "1640 records done\n",
      "1650 records done\n",
      "1660 records done\n",
      "1670 records done\n",
      "1680 records done\n",
      "1690 records done\n",
      "1700 records done\n",
      "1710 records done\n",
      "1720 records done\n",
      "1730 records done\n",
      "1740 records done\n",
      "1750 records done\n",
      "1760 records done\n",
      "1770 records done\n",
      "1780 records done\n",
      "1790 records done\n",
      "1800 records done\n",
      "1810 records done\n",
      "1820 records done\n",
      "1830 records done\n",
      "1840 records done\n",
      "1850 records done\n",
      "1860 records done\n",
      "1870 records done\n",
      "1880 records done\n",
      "1890 records done\n",
      "1900 records done\n",
      "1910 records done\n",
      "1920 records done\n",
      "1930 records done\n",
      "1940 records done\n",
      "1950 records done\n",
      "1960 records done\n",
      "1970 records done\n",
      "1980 records done\n",
      "1990 records done\n",
      "2000 records done\n",
      "2010 records done\n",
      "2020 records done\n",
      "2030 records done\n",
      "2040 records done\n",
      "2050 records done\n",
      "2060 records done\n",
      "2070 records done\n",
      "2080 records done\n",
      "2090 records done\n",
      "2100 records done\n",
      "2110 records done\n",
      "2120 records done\n",
      "2130 records done\n",
      "2140 records done\n",
      "2150 records done\n",
      "2160 records done\n",
      "2170 records done\n",
      "2180 records done\n",
      "2190 records done\n",
      "2200 records done\n",
      "2210 records done\n",
      "2220 records done\n",
      "2230 records done\n",
      "2240 records done\n",
      "2250 records done\n",
      "2260 records done\n",
      "2270 records done\n",
      "2280 records done\n",
      "2290 records done\n",
      "2300 records done\n",
      "2310 records done\n",
      "2320 records done\n",
      "2330 records done\n",
      "2340 records done\n",
      "2350 records done\n",
      "2360 records done\n",
      "2370 records done\n",
      "2380 records done\n",
      "2390 records done\n",
      "2400 records done\n",
      "2410 records done\n",
      "2420 records done\n",
      "2430 records done\n",
      "2440 records done\n",
      "2450 records done\n",
      "2460 records done\n",
      "2470 records done\n",
      "2480 records done\n",
      "2490 records done\n",
      "2500 records done\n",
      "2510 records done\n",
      "2520 records done\n",
      "2530 records done\n",
      "2540 records done\n",
      "2550 records done\n",
      "2560 records done\n",
      "2570 records done\n",
      "2580 records done\n",
      "2590 records done\n",
      "2600 records done\n",
      "2610 records done\n",
      "2620 records done\n",
      "2630 records done\n",
      "2640 records done\n",
      "2650 records done\n",
      "2660 records done\n",
      "2670 records done\n",
      "2680 records done\n",
      "2690 records done\n",
      "2700 records done\n",
      "2710 records done\n",
      "2720 records done\n",
      "2730 records done\n",
      "2740 records done\n",
      "2750 records done\n",
      "2760 records done\n",
      "2770 records done\n",
      "2780 records done\n",
      "2790 records done\n",
      "2800 records done\n",
      "2810 records done\n",
      "2820 records done\n",
      "2830 records done\n",
      "2840 records done\n",
      "2850 records done\n",
      "2860 records done\n",
      "2870 records done\n",
      "2880 records done\n",
      "2890 records done\n",
      "2900 records done\n",
      "2910 records done\n",
      "2920 records done\n",
      "2930 records done\n",
      "2940 records done\n",
      "2950 records done\n",
      "2960 records done\n",
      "2970 records done\n",
      "2980 records done\n",
      "2990 records done\n",
      "3000 records done\n",
      "3010 records done\n",
      "3020 records done\n",
      "3030 records done\n",
      "3040 records done\n",
      "3050 records done\n",
      "3060 records done\n",
      "3070 records done\n",
      "3080 records done\n",
      "3090 records done\n",
      "3100 records done\n",
      "3110 records done\n",
      "3120 records done\n",
      "3130 records done\n",
      "3140 records done\n",
      "3150 records done\n",
      "3160 records done\n",
      "3170 records done\n",
      "3180 records done\n",
      "3190 records done\n",
      "3200 records done\n",
      "3210 records done\n",
      "3220 records done\n",
      "3230 records done\n",
      "3240 records done\n",
      "3250 records done\n",
      "3260 records done\n",
      "3270 records done\n",
      "3280 records done\n",
      "3290 records done\n",
      "3300 records done\n",
      "3310 records done\n",
      "3320 records done\n",
      "3330 records done\n",
      "3340 records done\n",
      "3350 records done\n",
      "3360 records done\n",
      "3370 records done\n",
      "3380 records done\n",
      "3390 records done\n",
      "3400 records done\n",
      "3410 records done\n",
      "3420 records done\n",
      "3430 records done\n",
      "3440 records done\n",
      "3450 records done\n",
      "3460 records done\n",
      "3470 records done\n",
      "3480 records done\n",
      "3490 records done\n",
      "3500 records done\n",
      "3510 records done\n",
      "3520 records done\n",
      "3530 records done\n",
      "3540 records done\n",
      "3550 records done\n",
      "3560 records done\n",
      "3570 records done\n",
      "3580 records done\n",
      "3590 records done\n",
      "3600 records done\n",
      "3610 records done\n",
      "3620 records done\n",
      "3630 records done\n",
      "3640 records done\n",
      "3650 records done\n",
      "3660 records done\n",
      "3670 records done\n",
      "3680 records done\n",
      "3690 records done\n",
      "3700 records done\n",
      "3710 records done\n",
      "3720 records done\n",
      "3730 records done\n",
      "3740 records done\n",
      "3750 records done\n",
      "3760 records done\n",
      "3770 records done\n",
      "3780 records done\n",
      "3790 records done\n",
      "3800 records done\n",
      "3810 records done\n",
      "3820 records done\n",
      "3830 records done\n",
      "3840 records done\n",
      "3850 records done\n",
      "3860 records done\n",
      "3870 records done\n",
      "3880 records done\n",
      "3890 records done\n",
      "3900 records done\n",
      "3910 records done\n",
      "3920 records done\n",
      "3930 records done\n",
      "3940 records done\n",
      "3950 records done\n",
      "3960 records done\n",
      "3970 records done\n",
      "3980 records done\n",
      "3990 records done\n"
     ]
    }
   ],
   "source": [
    "#job_links = ['/job/data-science-lead-large-customer-sales-singapore-google-asia-pacific-4a23f0baa5c6bbdf7c07755a43ad57ff']\n",
    "for i, row in enumerate(url_list):\n",
    "    driver.get(row)\n",
    "    # Wait 5 second.\n",
    "    sleep(5)\n",
    "    html = driver.page_source\n",
    "    html = BeautifulSoup(html, 'lxml')\n",
    "    if (i % 10) == 0:\n",
    "        print(i, \"records done\")\n",
    "    for entry in html.find_all('div', {'class':'w-70-l w-60-ms w-100 pr2-l pr2-ms relative'}):\n",
    "    #for entry in html.find_all('div', {'class':'jobInfo w-100 dib v-top relative'}):\n",
    "        # Grab the job listings\n",
    "        try:\n",
    "            company = entry.find('p', {'name': 'company'}).text\n",
    "        except:\n",
    "            company = 0\n",
    "        try:\n",
    "            job_title = entry.find('h1', {'id': 'job_title'}).text\n",
    "        except:\n",
    "            job_title = 0\n",
    "        try:\n",
    "            address = entry.find('p', {'id': 'address'}).text\n",
    "        except:\n",
    "            address = 0\n",
    "        try:\n",
    "            employment_type = entry.find('p', {'id': 'employment_type'}).text\n",
    "        except:\n",
    "            employment_type = 0\n",
    "        try: \n",
    "            seniority = entry.find('p', {'id': 'seniority'}).text\n",
    "        except:\n",
    "            seniority = 0\n",
    "        try:\n",
    "            category = entry.find('p', {'id': 'job-categories'}).text\n",
    "        except:\n",
    "            category = 0\n",
    "        try:\n",
    "            salary = entry.find('div', {'class': 'lh-solid'}).text\n",
    "        except:\n",
    "            salary = 0\n",
    "        try:\n",
    "            salary_period = entry.find('span', {'class':'salary_type dib f5 fw4 black-60 pr1 i pb'}).text\n",
    "        except:\n",
    "            salary_period = 0\n",
    "        try:\n",
    "            requirements = entry.find('div', {'id':'requirements'}).text\n",
    "        except:\n",
    "            requirements = 0\n",
    "        # Add to the DataFrame.\n",
    "        jobs.loc[len(jobs)]=[company, job_title, address, employment_type, seniority, category, salary, salary_period, requirements]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3975, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>job_title</th>\n",
       "      <th>address</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>seniority</th>\n",
       "      <th>category</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_period</th>\n",
       "      <th>requirements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MONEYSMART SINGAPORE PTE. LTD.</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>GRANDE BUILDING, 8 COMMONWEALTH LANE 149555</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Executive</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>$5,000to$7,000</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>RequirementsCompetencies  Degree in Computer S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PORTCAST PTE. LTD.</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>32 CARPENTER STREET 059911</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Middle Management</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>$2,200to$6,000</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>Requirements●  Comfortable working with large ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SINGAPORE PRESS HOLDINGS LIMITED</td>\n",
       "      <td>Data Visualisation Designer</td>\n",
       "      <td>NEWS CENTRE, 1000 TOA PAYOH NORTH 318994</td>\n",
       "      <td>Permanent</td>\n",
       "      <td>Junior Executive</td>\n",
       "      <td>Design</td>\n",
       "      <td>$3,500to$4,500</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>Requirements Prior experience in a data visual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GRABTAXI HOLDINGS PTE. LTD.</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>OUE DOWNTOWN, 6 SHENTON WAY 068809</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Executive</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>RequirementsThe must haves:  A Bachelor's/Mast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMAZON ASIA-PACIFIC RESOURCES PRIVATE LIMITED</td>\n",
       "      <td>Data Center Engineering Project Engineer APAC</td>\n",
       "      <td>AIA TOWER, 1 ROBINSON ROAD 048542</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Design, Engineering</td>\n",
       "      <td>$9,000to$12,000</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>RequirementsBasic Qualifications -  Minimum 5 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         company  \\\n",
       "0                 MONEYSMART SINGAPORE PTE. LTD.   \n",
       "1                             PORTCAST PTE. LTD.   \n",
       "2               SINGAPORE PRESS HOLDINGS LIMITED   \n",
       "3                    GRABTAXI HOLDINGS PTE. LTD.   \n",
       "4  AMAZON ASIA-PACIFIC RESOURCES PRIVATE LIMITED   \n",
       "\n",
       "                                       job_title  \\\n",
       "0                                  Data Engineer   \n",
       "1                                 Data Scientist   \n",
       "2                    Data Visualisation Designer   \n",
       "3                                   Data Analyst   \n",
       "4  Data Center Engineering Project Engineer APAC   \n",
       "\n",
       "                                       address employment_type  \\\n",
       "0  GRANDE BUILDING, 8 COMMONWEALTH LANE 149555       Full Time   \n",
       "1                   32 CARPENTER STREET 059911       Full Time   \n",
       "2     NEWS CENTRE, 1000 TOA PAYOH NORTH 318994       Permanent   \n",
       "3           OUE DOWNTOWN, 6 SHENTON WAY 068809       Full Time   \n",
       "4            AIA TOWER, 1 ROBINSON ROAD 048542       Full Time   \n",
       "\n",
       "           seniority                category           salary salary_period  \\\n",
       "0          Executive  Information Technology   $5,000to$7,000       Monthly   \n",
       "1  Middle Management             Engineering   $2,200to$6,000       Monthly   \n",
       "2   Junior Executive                  Design   $3,500to$4,500       Monthly   \n",
       "3          Executive  Information Technology                0                 \n",
       "4       Professional     Design, Engineering  $9,000to$12,000       Monthly   \n",
       "\n",
       "                                        requirements  \n",
       "0  RequirementsCompetencies  Degree in Computer S...  \n",
       "1  Requirements●  Comfortable working with large ...  \n",
       "2  Requirements Prior experience in a data visual...  \n",
       "3  RequirementsThe must haves:  A Bachelor's/Mast...  \n",
       "4  RequirementsBasic Qualifications -  Minimum 5 ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save to csv\n",
    "jobs.to_csv('jobs_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Analysis to be continued in another python file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION 2: Factors that distinguish job category\n",
    "\n",
    "Using the job postings you scraped for part 1 (or potentially new job postings from a second round of scraping), identify features in the data related to job postings that can distinguish job titles from each other. There are a variety of interesting ways you can frame the target variable, for example:\n",
    "- What components of a job posting distinguish data scientists from other data jobs?\n",
    "- What features are important for distinguishing junior vs. senior positions?\n",
    "- Do the requirements for titles vary significantly with industry (e.g. healthcare vs. government)?\n",
    "\n",
    "You may end up making multiple classification models to tackle different questions. Be sure to clearly explain your hypotheses and framing, any feature engineering, and what your target variables are. The type of classification model you choose is up to you. Be sure to interpret your results and evaluate your models' performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS PROBLEM\n",
    "\n",
    "Your boss would rather tell a client incorrectly that they would get a lower salary job than tell a client incorrectly that they would get a high salary job. Adjust one of your models to ease his mind, and explain what it is doing and any tradeoffs. Plot the ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5. Answer the salary discussion by using your model to explain the tradeoffs between detecting high vs low salary positions.\n",
    "\n",
    "# 6. Convert your executive summary into a public blog post of at least 500 words, in which you document your approach in a tutorial for other aspiring data scientists. Link to this in your notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggestions for Getting Started\n",
    "\n",
    "1. Collect data from [Indeed.com](www.indeed.com) (or another aggregator) on data-related jobs to use in predicting salary trends for your analysis.\n",
    "  - Select and parse data from *at least 1000 postings* for jobs, potentially from multiple location searches.\n",
    "2. Find out what factors most directly impact salaries (e.g. title, location, department, etc).\n",
    "  - Test, validate, and describe your models. What factors predict salary category? How do your models perform?\n",
    "3. Discover which features have the greatest importance when determining a low vs. high paying job.\n",
    "  - Your Boss is interested in what overall features hold the greatest significance.\n",
    "  - HR is interested in which SKILLS and KEY WORDS hold the greatest significance.   \n",
    "4. Author an executive summary that details the highlights of your analysis for a non-technical audience.\n",
    "5. If tackling the bonus question, try framing the salary problem as a classification problem detecting low vs. high salary positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
